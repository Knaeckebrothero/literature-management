{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T17:17:07.473925Z",
     "start_time": "2025-01-20T17:17:07.469796Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "# Setup the database\n",
    "def setup_database(db_path: str = 'literature.db'):\n",
    "    \"\"\"\n",
    "    Function to create the SQLite database, set up the connection,\n",
    "    and create tables if they do not already exist.\n",
    "    \"\"\"\n",
    "    connector = sqlite3.connect(db_path)\n",
    "    cursor = connector.cursor()\n",
    "\n",
    "    # Main table for papers\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS papers (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        doi TEXT UNIQUE NOT NULL,\n",
    "        title TEXT,\n",
    "        publication_year INTEGER,\n",
    "        authors TEXT,\n",
    "        venue TEXT,\n",
    "        volume TEXT,\n",
    "        publication_type TEXT,\n",
    "        publication_source TEXT,\n",
    "        processed BOOLEAN DEFAULT 0,\n",
    "        file_path TEXT DEFAULT NULL\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Table for paper assessments\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS paper_assessments (\n",
    "        paper_id INTEGER PRIMARY KEY,\n",
    "        is_neurosymbolic BOOLEAN,\n",
    "        is_development BOOLEAN,\n",
    "        paper_type TEXT,\n",
    "        summary TEXT,\n",
    "        takeaways TEXT,\n",
    "        assessment_date TIMESTAMP,\n",
    "        FOREIGN KEY (paper_id) REFERENCES papers (id)\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Table for keywords\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS keywords (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        keyword TEXT UNIQUE\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Relationship table for keywords and papers\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS rel_keywords_papers (\n",
    "        paper_id INTEGER,\n",
    "        keyword_id INTEGER,\n",
    "        FOREIGN KEY (paper_id) REFERENCES papers (id),\n",
    "        FOREIGN KEY (keyword_id) REFERENCES keywords (id)\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    connector.commit()\n",
    "    connector.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25924a186f50796b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T17:17:07.540356Z",
     "start_time": "2025-01-20T17:17:07.497941Z"
    }
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the full text from a PDF using PyPDF2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        all_text = []\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text() or \"\"\n",
    "            all_text.append(page_text)\n",
    "        return \"\\n\".join(all_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def get_first_page_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from the first page of a PDF.\n",
    "    Returns an empty string if no pages exist or an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) > 0:\n",
    "            first_page = reader.pages[0]\n",
    "            return first_page.extract_text() or \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# This prompt instructs the agent to extract both abstract and keywords.\n",
    "# If the first page doesn't contain them, it's allowed to call the PaperRetriever tool\n",
    "# to query the rest of the paper.\n",
    "# The agent must return the data in JSON form.\n",
    "ABSTRACT_KEYWORDS_PROMPT = \"\"\"\n",
    "You are extracting information from a research paper.\n",
    "\n",
    "Below is the text of the first page:\n",
    "{first_page_text}\n",
    "\n",
    "Your goal:\n",
    "1. Extract the paper's abstract.\n",
    "2. Extract the paper's keywords (as a list of words or phrases).\n",
    "\n",
    "If the first page does not contain the abstract, the full abstract, or the keywords, \n",
    "you have access to a 'PaperRetriever' tool that can retrieve more text from the paper.\n",
    "\n",
    "Return valid JSON with the structure:\n",
    "{{\n",
    "  \"abstract\": \"...\",\n",
    "  \"keywords\": [\"...\", \"...\"]\n",
    "}}\n",
    "\n",
    "- If no abstract is found, use an empty string: \"abstract\": \"\"\n",
    "- If no keywords are found, use an empty list: \"keywords\": []\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import Tool\n",
    "\n",
    "\n",
    "def create_paper_retriever_tool(vectorstore: Chroma) -> Tool:\n",
    "    \"\"\"\n",
    "    Create a tool that can be called by the agent to do a similarity search\n",
    "    over the paper's text.\n",
    "    \"\"\"\n",
    "    def retrieval_tool(query: str) -> str:\n",
    "        docs = vectorstore.similarity_search(query, k=2)\n",
    "        contents = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "        return contents\n",
    "\n",
    "    return Tool(\n",
    "        name=\"PaperRetriever\",\n",
    "        func=retrieval_tool,\n",
    "        description=(\n",
    "            \"Retrieves relevant text from the stored papers for the query. \"\n",
    "            \"Use it if you need to find the abstract or the keywords that are not on the first page.\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bc067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "db_path: str = 'literature.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 1) LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", # gpt-4-turbo gpt-4o-mini\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 2) Embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 3) Chroma vector store\n",
    "persist_directory = \"./chroma_store\"\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"papers_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# 4) Tools\n",
    "def create_paper_retriever_tool(vectorstore: Chroma) -> Tool:\n",
    "    def retrieval_tool(query: str) -> str:\n",
    "        docs = vectorstore.similarity_search(query, k=2)\n",
    "        contents = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "        return contents\n",
    "    return Tool(\n",
    "        name=\"PaperRetriever\",\n",
    "        func=retrieval_tool,\n",
    "        description=\"Retrieves relevant text from the stored papers for the query.\"\n",
    "    )\n",
    "\n",
    "retriever_tool = create_paper_retriever_tool(vectorstore)\n",
    "\n",
    "# 5) Agent\n",
    "agent = initialize_agent(\n",
    "    tools=[retriever_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 6) Get a set of papers from the DB\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT id, title, file_path\n",
    "    FROM papers\n",
    "    WHERE file_path IS NOT NULL\n",
    "    AND id = 7\n",
    "\"\"\")\n",
    "paper_rows = cursor.fetchall()\n",
    "\n",
    "for paper_id, title, file_path in paper_rows:\n",
    "    print(f\"Processing Paper ID={paper_id}: {title}\")\n",
    "\n",
    "    # a) Extract the full text and the first page text\n",
    "    full_text = extract_text_from_pdf(file_path)\n",
    "    first_page = get_first_page_text(file_path)\n",
    "\n",
    "    # b) Insert the entire PDF text into Chroma, \n",
    "    #    so the agent can retrieve from it if needed.\n",
    "    metadata = {\"paper_id\": paper_id, \"title\": title}\n",
    "    doc = Document(page_content=full_text, metadata=metadata)\n",
    "    vectorstore.add_documents([doc])\n",
    "\n",
    "    # c) Prepare the prompt\n",
    "    prompt = ABSTRACT_KEYWORDS_PROMPT.format(first_page_text=first_page)\n",
    "\n",
    "    # d) Run the agent\n",
    "    try:\n",
    "        agent_response = agent.run(prompt)\n",
    "        print(\"Agent raw response:\\n\", agent_response)\n",
    "\n",
    "        # e) Parse JSON\n",
    "        try:\n",
    "            extraction = json.loads(agent_response)\n",
    "            abstract = extraction.get(\"abstract\", \"\")\n",
    "            keywords = extraction.get(\"keywords\", [])\n",
    "        except json.JSONDecodeError as decode_err:\n",
    "            print(\"Could not parse JSON from agent response:\", decode_err)\n",
    "            abstract = \"\"\n",
    "            keywords = []\n",
    "\n",
    "        # f) Do something with the results\n",
    "        #    For example, store them in the 'papers' table or 'paper_assessments' table.\n",
    "        #    If 'papers' table doesn't have these columns, you could add them or store them elsewhere.\n",
    "        #    For demonstration, we'll just print them:\n",
    "        print(f\"Extracted Abstract:\\n{abstract}\")\n",
    "        print(f\"Extracted Keywords: {keywords}\")\n",
    "\n",
    "        # Example of storing them if 'papers' had columns 'extracted_abstract' & 'extracted_keywords':\n",
    "        \"\"\"\n",
    "        ALTER TABLE papers ADD COLUMN extracted_abstract TEXT;\n",
    "        ALTER TABLE papers ADD COLUMN extracted_keywords TEXT;\n",
    "        \"\"\"\n",
    "        # cursor.execute(\"\"\"\n",
    "        #     UPDATE papers\n",
    "        #     SET extracted_abstract = ?, \n",
    "        #         extracted_keywords = ?\n",
    "        #     WHERE id = ?\n",
    "        # \"\"\", (abstract, \", \".join(keywords), paper_id))\n",
    "        # conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data for paper {paper_id}: {e}\")\n",
    "\n",
    "# Close DB\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
